{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to show various techniques for checking normal distribution:\n",
    "\n",
    "1. Normal distribution parameters check\n",
    "2. Hypothesis testing\n",
    "3. Graphic representation of density functions.\n",
    "\n",
    "Except for working with above methods, I will perform needed dataset modification in order to typos desposal and converting numerical variables into categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e5f3f013fbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('books.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_lines_percent = round(4/(df.shape[0]+4)*100,4)\n",
    "skipped_lines_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipped lines account for about 0.0359 % of length of whole dataset, hence such skipping is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Take a look at basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of **11123 rows and 12 columns**. The **columns names** are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataframe modification \n",
    "### 4.1 Fix column names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will rename whitespace in \"num_pages\" column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '')\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Remove needless columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns like:\n",
    "* bookID\n",
    "* isbn\n",
    "* isbn13\n",
    "* title\n",
    "* authors\n",
    "\n",
    "are not interesting from the viewpoint of distribution analysis, so they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of columns before removing: {df.shape[1]}')\n",
    "df = df.drop(['bookID', 'isbn', 'isbn13', 'title', 'authors'], axis=1)\n",
    "print(f'Number of columns after removing: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Convert some categorical data into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence column \"language_code\" has only 27 unique values, it can be easy mapped to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language codes with prefix 'en-' like: en-US, en-CA, en-GB will be replaced by 'eng'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language_code = df.language_code.replace(to_replace ='en-..', value = 'eng', regex = True)\n",
    "np.sort(df.language_code.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that mentioned values have been replaced by 'eng'. Last thing is to convert this column to a column with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df.language_code.unique()\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "df.language_code = enc.fit_transform(df.language_code.values.reshape(-1, 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'before': before,\n",
    "                   'after': df.language_code.unique()}).sort_values(by='before')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of \"language code\" values will enable the further distribution analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature engineering\n",
    "\n",
    "### 4.4.1 Publication date\n",
    "\"publication_date\" may be valuable for distribution analysis, especially when years will be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.publication_date.str.rsplit(\"/\", n=3, expand=True)[2].astype(int)\n",
    "# n=3 because value is splitted into 3 parts: day, month and year\n",
    "# [2] because we are interested only in 'year'\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid data leakage \"publication_date\" will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['publication_date'], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normal distribution analysis\n",
    "I will perform the analysis going through 3 approaches:\n",
    "* using basic stats to see normal distribution parameters.\n",
    "* hypothesis testing of normal distribution\n",
    "* graphic representation of density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last glance at basic statistics to check if datapoints looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Normal distribution parameters check\n",
    "\n",
    "Parameters that are indicative for normal distribution are:\n",
    "* mean \n",
    "* median \n",
    "* kurtosis\n",
    "* skewness.\n",
    "\n",
    "The mean and median [should have the same value](https://en.wikipedia.org/wiki/Normal_distribution), and kurtosis and skewness [be equal to 0](https://en.wikipedia.org/wiki/Normal_distribution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(['mean', 'median', 'kurtosis', 'skew']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and median have similar values for: \n",
    "* average_rating (left-skewed distribution)\n",
    "* num_pages (right-skewed distribution)\n",
    "* language_code (right-skewed distribution)\n",
    "* year (with a skew that is the closest to 0, left-skewed distribution)\n",
    "\n",
    "The \"year\" and \"average_rating\" are our front-runners in the race for normal distribution ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "p_value_list = []\n",
    "alpha = 0.05\n",
    "\n",
    "for i in df._get_numeric_data().columns:\n",
    "    p_value = scipy.stats.normaltest(df[i])[1] # to get only p_value without a statistic\n",
    "    p_value_list.append(p_value)\n",
    "    if p_value < alpha:\n",
    "        results.append('rejected')\n",
    "    else:\n",
    "        results.append('not rejected')\n",
    "        \n",
    "pd.DataFrame(data={'variable': df._get_numeric_data().columns,\n",
    "                    'p_value': p_value_list,\n",
    "                    'null hypothesis': results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to hypothesis testing, none of variables comes from a normal distribution. It's hard to find a feature that is the closest to be normal because all p value are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Graphic representation of density functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3,2, figsize=(15, 10))\n",
    "sns.distplot(df.average_rating, color='skyblue', ax=axes[0, 0])\n",
    "sns.distplot(df.num_pages, color='olive', ax=axes[0, 1])\n",
    "sns.distplot(df.ratings_count, color='gold', ax=axes[1, 0])\n",
    "sns.distplot(df.text_reviews_count, color='teal', ax=axes[1, 1])\n",
    "sns.distplot(df.year, color='skyblue', ax=axes[2, 0])\n",
    "sns.countplot(x = 'language_code', data = df, ax=axes[2,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, \"average_rating\" is the most normal variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conlusion\n",
    "\n",
    "The dataset consisted of 12 columns. Five of them (bookID, isbn, isbn13, title and authors) have been removed because checking them for statistics wasn't reasonable. \n",
    "The column \"publication_date\" has been replaced by column \"year\".  \n",
    "Eventually, the dataset had 7 columns: categorical (\"language_code\" and \"publisher\") and numerical (the rest).\n",
    "\n",
    "Use of 3 different methods showed different results. Despite the fact that the distribution of \"average_rating\" variable looks like a normal distribution (5.3), then none of the numerical variables hasn't a normal distribution (5.1 and 5.2). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
